{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R_13 Mastadon Data Processing and Bulk Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "def get_sentiment(x):\n",
    "    \"\"\" Helper to extract sentiment \"\"\"\n",
    "\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sia_out = sia.polarity_scores(x)\n",
    "\n",
    "    neg = sia_out['neg']\n",
    "    pos = sia_out['pos']\n",
    "    neu = sia_out['neu']\n",
    "    compound = sia_out['compound']\n",
    "\n",
    "    sentiment = np.argmax([sia_out['neg'], sia_out['neu'], sia_out['pos']]) - 1\n",
    "\n",
    "    return neg, pos, neu, compound, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract(input):\n",
    "    \"\"\" Helper to extract text in betweein paragraph tags \"\"\"\n",
    "    \n",
    "    # Use regular expression to extract the first text between <p> and </p> tags\n",
    "    match = re.search('<p>(.*?)</p>', input)\n",
    "    if match:\n",
    "        # Extract the matched text group\n",
    "        text = match.group(1)\n",
    "        # Remove any HTML tags within the matched text\n",
    "        clean_text = re.sub('<.*?>', '', text)\n",
    "\n",
    "        return clean_text\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mastadon(doc):\n",
    "    \"\"\" Process Mastadon data \"\"\"\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for toot in doc:\n",
    "\n",
    "        # skip non english\n",
    "        if toot['doc']['language'] != 'en':\n",
    "            continue\n",
    "\n",
    "        document = {}\n",
    "\n",
    "        # add in the columns we are interested in\n",
    "        document['_id'] = toot['id']\n",
    "        document['author_id'] = str(toot['doc']['account']['id'])\n",
    "        if 'key_match' in toot['doc']:\n",
    "            document['partial_match'] = 1\n",
    "        else:\n",
    "            document['partial_match'] = 0\n",
    "        document['date'] = toot['doc']['created_at'][:10]\n",
    "        document['text'] = extract(toot['doc']['content'])\n",
    "\n",
    "        # get the sentiment output\n",
    "        neg, pos, neu, compound, sentiment = get_sentiment(document['text'])\n",
    "\n",
    "        document['neg_score'] = neg\n",
    "        document['neu_score'] = neu\n",
    "        document['pos_score'] = pos\n",
    "        document['compound_score'] = compound\n",
    "        document['sentiment'] = sentiment\n",
    "    \n",
    "        out.append(document)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "processed_mastadon_toots = []\n",
    "\n",
    "url = 'http://172.26.130.136:5984/mastodon_social_politics/_all_docs'\n",
    "params = {'include_docs': 'true', 'limit' : 10000}\n",
    "\n",
    "# Authenticate if needed\n",
    "auth = ('admin', 'password')\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Iteratively download data\n",
    "while True:\n",
    "    response = requests.get(url, params=params, auth=auth)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if len(data['rows']) == 0:\n",
    "            # No more documents\n",
    "            break\n",
    "        doc = data['rows']\n",
    "        \n",
    "        processed_mastadon_toots.extend(process_mastadon(doc))\n",
    "\n",
    "        # Process document\n",
    "        params['skip'] = params.get('skip', 0) + 10000\n",
    "        \n",
    "        i+=10000\n",
    "        print(i)\n",
    "        \n",
    "    else:\n",
    "        print(f'Request failed with status code {response.status_code}')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_json = eval(str(processed_mastadon_toots))\n",
    "with open('./../data/curated/Mastadon_Cleaned/toot_cdb_bulk.json', 'w') as f:\n",
    "    json.dump(reformatted_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390598"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many toots\n",
    "len(reformatted_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move onto CDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ok\":true}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    12  100    12    0     0    119      0 --:--:-- --:--:-- --:--:--   120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='curl -X PUT http://172.26.133.251:5984/toot_database -u group9_admin:group9_H1', returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new database\n",
    "subprocess.run(f'curl -X PUT http://172.26.133.251:5984/toot_database -u group9_admin:group9_H1', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload toots\n",
    "for i in range(len(reformatted_json)//10000):\n",
    "    out = {'docs': reformatted_json[i*10000:(i+1)*10000]}\n",
    "    json_data = json.dumps(out).encode('utf-8')\n",
    "    subprocess.run(['curl', '-X', 'POST', f'http://172.26.133.251:5984/toot_database/_bulk_docs', '--header', 'Content-Type: application/json', '--data-binary', '@-', '-u', 'group9_admin:group9_H1'], input=json_data)\n",
    "\n",
    "out = {'docs': reformatted_json[(i+1)*10000:len(reformatted_json)]}\n",
    "json_data = json.dumps(out).encode('utf-8')\n",
    "subprocess.run(['curl', '-X', 'POST', f'http://172.26.133.251:5984/toot_database/_bulk_docs', '--header', 'Content-Type: application/json', '--data-binary', '@-', '-u', 'group9_admin:group9_H1'], input=json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
